# ğŸ¯ ARQA - Arabic Question Answering System

A system for processing Arabic HTML documents and answering questions about their content.

## ğŸš€ What Works Right Now

âœ… **Arabic HTML Processing** - Convert HTML documents to searchable text

```bash
# Install basic requirements
pip install beautifulsoup4 lxml

# Run the demo
python test_html_demo.py
```

## ğŸ“ Simple Project Structure

```
src/arqa/
â”œâ”€â”€ simple_ingest.py    # âœ… Working HTML processor
â”œâ”€â”€ ingest.py          # âŒ Advanced version (needs complex setup)
â”œâ”€â”€ retriever.py       # ğŸ”„ Document search (TODO)
â”œâ”€â”€ reader.py          # ğŸ”„ Question answering (TODO)  
â””â”€â”€ api.py             # ğŸ”„ Web API (TODO)

test_html_demo.py      # âœ… Working demo
```

## ğŸ® Try It Out

The demo will:
1. Create sample Arabic HTML files
2. Process them into clean, searchable text
3. Show processing statistics
4. Save results to `test_output/`

## ğŸ“š Learn More

- ğŸ“– **[Simple Explanation](SIMPLE_EXPLANATION.md)** - What is this system?
- ğŸ“ **[HTML Processing Guide](HTML_INGESTION_GUIDE.md)** - Technical details
- ğŸ“Š **[Success Report](INGESTION_SUCCESS_REPORT.md)** - What's working now

## ğŸ”§ Next Steps

The system is built in phases:
1. âœ… **HTML Processing** (DONE - working!)
2. ğŸ”„ **Document Search** (TODO)  
3. ğŸ”„ **Question Answering** (TODO)
4. ğŸ”„ **Web Interface** (TODO)

## ğŸ’¡ Example

Input: Arabic HTML file â†’ Output: Clean searchable text

```
HTML: <h1>Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</h1><p>ØªØ·ÙˆØ± Ø³Ø±ÙŠØ¹...</p>
JSON: {"content": "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØªØ·ÙˆØ± Ø³Ø±ÙŠØ¹...", "title": "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"}
```

## ğŸ—ï¸ System Architecture

The ARQA system consists of four main phases, each with comprehensive documentation:

### Phase 1: Document Ingestion (`ingest.py`)
**Purpose**: Preprocess and index Arabic documents for efficient retrieval.

**Key Features**:
- Arabic text preprocessing with CAMEL-tools and Farasa
- Document normalization and vector indexing
- FAISS-based semantic search preparation

ğŸ“– **[Complete Phase 1 Documentation](docs/phase1_ingestion.md)**

### Phase 2: Document Retrieval (`retriever.py`)
**Purpose**: Find semantically relevant documents for a given Arabic query.

**Key Features**:
- Dense passage retrieval with Arabic BERT embeddings
- Query preprocessing and semantic similarity matching
- Configurable relevance scoring and ranking

ğŸ“– **[Complete Phase 2 Documentation](docs/phase2_retrieval.md)**

### Phase 3: Reading Comprehension (`reader.py`)
**Purpose**: Extract precise answers from retrieved documents using question answering models.

**Key Features**:
- Arabic QA models with confidence scoring
- Multi-document answer extraction and aggregation
- Support for various question types and answer patterns

ğŸ“– **[Complete Phase 3 Documentation](docs/phase3_reading.md)**

### Phase 4: API Service (`api.py`)
**Purpose**: Provide RESTful API endpoints for the complete QA pipeline.

**Key Features**:
- FastAPI framework with automatic documentation
- Complete pipeline orchestration and error handling
- Production-ready deployment with monitoring

ğŸ“– **[Complete Phase 4 Documentation](docs/phase4_api.md)**

## ğŸ“š Complete Documentation

For comprehensive documentation covering implementation details, configuration options, performance optimization, and troubleshooting guides:

**[ğŸ“– Full Documentation Index](docs/README.md)**

### Available Endpoints:
- `POST /ingest` - Ingest documents into the system
- `POST /search` - Search for relevant documents  
- `POST /qa` - Complete question answering pipeline
- `GET /health` - System health check
- `POST /update-embeddings` - Refresh document embeddings

## ğŸš€ Quick Start

### ğŸ“„ HTML Article Processing (Enhanced)

The ARQA system now includes enhanced HTML ingestion with Arabic text normalization:

```python
from src.arqa.ingest import DocumentIngestor

# Initialize enhanced ingestor
ingestor = DocumentIngestor()

# Process HTML articles from directory
ingestor.ingest_from_directory("./html_articles")
ingestor.save_index()
```

ğŸ¯ **[Complete HTML Ingestion Guide](HTML_INGESTION_GUIDE.md)** - Detailed setup and usage

### ğŸ–¥ï¸ Server Setup

1. **Install Dependencies**:
```powershell
pip install -r requirements.txt
```

2. **Run the Server**:
```powershell
python main.py
```

3. **Access API Documentation**:
- Interactive docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ“Š Usage Examples

### Ingest Documents
```python
import requests

documents = [
    {
        "content": "Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†Ø§",
        "meta": {"title": "Document 1", "source": "source1"}
    }
]

response = requests.post("http://localhost:8000/ingest", 
                        json={"documents": documents})
```

### Ask Questions
```python
response = requests.post("http://localhost:8000/qa", 
                        json={"question": "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ØŸ", "top_k": 3})
```

## ğŸ”§ Configuration

- **Index Path**: Default FAISS index location: `./faiss_index`
- **Models**: Default Arabic BERT models for embeddings and QA
- **Server**: Default host: `0.0.0.0`, port: `8000`

## ğŸ“ API Response Format

### Question Answering Response
```json
{
    "question": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø·Ø±ÙˆØ­",
    "answers": [
        {
            "answer": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©",
            "score": 0.95,
            "start": 10,
            "end": 25,
            "document_id": "doc_1",
            "document_meta": {},
            "document_score": 0.88
        }
    ],
    "processing_time": 1.23
}
```

## ğŸ¯ Features

- âœ… Arabic text preprocessing with linguistic tools
- âœ… Semantic document retrieval with FAISS
- âœ… Extractive question answering with BERT
- âœ… RESTful API with comprehensive documentation
- âœ… Scalable architecture with modular design
- âœ… Error handling and logging
- âœ… CORS support for web applications

## ğŸ” Technical Details

### Models Used
- **Embeddings**: `aubmindlab/bert-base-arabertv02`
- **Question Answering**: `aubmindlab/arabert-qa`
- **Preprocessing**: CAMEL-tools + Farasa

### Dependencies
- `camel-tools`: Arabic morphological analysis
- `farasa==0.0.9`: Arabic text segmentation  
- `transformers`: Hugging Face transformer models
- `haystack[faiss]`: Document store and retrieval
- `fastapi`: Web framework
- `uvicorn[standard]`: ASGI server
